---
title: "Data Mining Abnb Data"
output: html_document
---
---
  title: "Data Mining AirBnB Data"
output:
  pdf_document: default
html_notebook: default
---
  
```{r, message = FALSE }
library(tidyverse)
library(caret)
library(stringr)
library(fpp2)
library(FNN)
library(qdapRegex)
library(e1071)
library(rpart)
library(rpart.plot)
library(MASS)
library(fastDummies)
options(scipen = 999)
set.seed(170)
```


I. Missing Values

```{r}
cities<-read.csv("metad699_train.csv", header=TRUE, sep=",")
la.df<- filter(cities, city=="LA")
summary(la.df$review_scores_rating)
colSums(is.na(la.df))
# rating.df <- filter(la.df, is.na(review_scores_rating))
# rating0.df <- filter(rating.df, rating.df$number_of_reviews == 0)
clean.df <- drop_na(la.df, review_scores_rating)
clean.df <- drop_na(clean.df, bathrooms)
clean.df <- drop_na(clean.df, bedrooms)
clean.df <- drop_na(clean.df, beds)
clean.df[c(23)] <- lapply(clean.df[c(23)], trimws)
clean.df[clean.df==""]<- NA
clean.df$neighbourhood[is.na(clean.df$neighbourhood)] <- "Unlisted"
clean.df$host_has_profile_pic[is.na(clean.df$host_has_profile_pic)] <- "f"
clean.df$host_identity_verified[is.na(clean.df$host_identity_verified)] <- "f"
clean.df$host_since[is.na(clean.df$host_since)] <- clean.df$first_review
clean.df$thumbnail_url[is.na(clean.df$thumbnail_url)] <- "none"
clean.df$zipcode[is.na(clean.df$zipcode)] <- "99999"
clean.df$host_response_rate[is.na(clean.df$host_response_rate)] <- "0%"
clean.df$neighbourhood <- as.factor(clean.df$neighbourhood)
# clean.df <- clean.df[, -26]
colSums(is.na(clean.df))
```

**After importing the initial .csv and filtering it to only include the city we are analyzing (Los Angeles, CA), we examined the resulting data frame to determine if there was any data missing. Of the 22,453 observations for LA, the raw data contained values of NA in the variables "bathrooms" (66),  "review_scores_rating" (5267), "bedrooms" (27) and "beds" (42). After some team debate it was decided that bathrooms, bedrooms and beds were a small enough portion of our total data set as to be statistically insignificant and could therefore be removed from the data frame. The variable "review_scores_rating" was a bigger challenge, because it represented ~23.4% of the total records in the data set. Some consideration was given to assigning the 'mean' review_scores_rating of the remaining records to the NAs, but due to the size of the dataset we were concerned that this method of dealing with the missing variables would skew the data making the variable less meaningful in any analysis. A deeper look at the NAs in review_scores_rating showed that of the 5267 observations 5041 had zero number_of_reviews. This indicated to us that these units had never been rented and any pricing for those units would not necessarily be reflective of the rental market. Therefore, we decided that any record with an NA in review_scores_rating should also be omitted from our analysis. Finally, we trimmed any whitespace from the dataframe, set empty fields to NA and rechecked the data. All of the new NAs were in character fields so dummy data was applied to replace the remaining NAs. This left us a clean dataframe with which to begin our analysis.**
  
  II. Summary Statistics

```{r}
summary(clean.df$log_price)
summary(clean.df$review_scores_rating)
summary(clean.df$accommodates)
summary(clean.df$bedrooms)
summary(clean.df$beds)
summary(clean.df$bathrooms)

clean.df %>%
  group_by(neighbourhood) %>%
  summarise_at(c("log_price", "review_scores_rating", "accommodates", "bedrooms", "beds", "bathrooms"), mean, na.rm = TRUE)

clean.df %>%
  group_by(property_type) %>%
  summarise_at(c("log_price", "review_scores_rating", "accommodates", "bedrooms", "beds", "bathrooms"), mean, na.rm = TRUE)

clean.df %>%
  group_by(room_type) %>%
  summarise_at(c("log_price", "review_scores_rating", "accommodates", "bedrooms", "beds", "bathrooms"), mean, na.rm = TRUE)

clean.df %>%
  group_by(bed_type) %>%
  summarise_at(c("log_price", "review_scores_rating", "accommodates", "bedrooms", "beds", "bathrooms"), mean, na.rm = TRUE)

```

**Looking at our cleaned dataset, I felt the best course of action was to begin by using the summary function to examine several of the numeric values in the dataset and see what information we could gather. Looking at the results several interesting trends emerge, primarily the existence of large tails in the numbered amenities, like bedrooms and bathrooms. For all of these values, the distance between the minimum value and the third quartile was fairly small. This indicates a relatively homogeneous dataset, with most properties having relatively similar number of bedrooms, baths, etc. However, the distance from the third quartile and the max value was extreme, between 4 to 16 times the distance of a given variables distance from minimum to third quartile. This indicates that while the average number of any given amenity skews low there are significant outliers in the dataset. At the same time review scores appeared to be skewed in the opposite direction with a minimum score of 20 while the scores from the first thru the third quartile fell between 92 and 100. The Log price appears to follow a much more regular distribution. **
  
  **Next I decided to look at the mean value of these six variables grouped by various characteristics. This shows me some interesting things, such as the highest average log price is associated with the Malibu neighbourhood and the castle property type and that rentals that include the whole property and a full bed generally cost more than their counterparts.**
  
  III. Visualization

```{r}
vplot <- ggplot(data = clean.df, mapping = aes(x=room_type, y=log_price)) + geom_violin(fill = "red") + ggtitle("Room Vs Price")
vplot

vplot2 <- ggplot(clean.df, aes(x=log_price, fill=property_type)) +geom_histogram(bins = 30)
vplot2

ggplot(clean.df, aes( x =property_type , y = log_price , color = room_type ,size = accommodates)) + geom_point()+ theme(axis.text.x = element_text(angle = 90))

ggplot(clean.df, aes(y = bedrooms , fill = property_type)) + geom_bar() + theme(axis.text.x = element_text(angle = 90))

pairs(clean.df[, c(2,6,7)])
```

**In order to get a better handle on the data I created several plots to give us a viual representation of various aspects of the data. First I created a violin plot giving us a comparison of the prices for any given room type. This plot shows us the entire range of prices by room type in a manner that allows us to observe the distribution of prices and any overlap between property types. As seen from the plot, it is clear the average log price is higher than the middle of the violin; there are tails that go up and down. For an entire home/ apartment it can (in some cases) be the least most expensive but the bulk of it/average is higher compared to private and shared room. When looking at the private room it shows the average of that is cheaper than an entire apartment but there is a tail, which increases very close to the entire house/apartment price. The second plot shows how many of each property (30 properties/bins) there are based on a bell curve. The right hand side shows the properties color code and the Y-axis shows the count. There is a variance in pricing across all property types. From this plot, it is shown that apartments have a big bell curve, which indicates it has the most volume compared to villas or trains. House also has a huge volume.**
  
  **The third plot is similar to the second plot and shows different properties in LA. As seen in this plot, there are three colors and each represents an entire apartment, shares room, or private room. In addition to that, the four black dots show how many people each property accommodates along with its average price. Right off the bat, when looking at this plot it is seen that there are a lot of entire apartments that accommodate more then 12 in apartments and houses. It is also shown that not that many places accommodate for four people in a shared room. The fourth plot explains how many bedrooms each property type has. The fill shows each property type and compares it to other property types. There are 30 property types and from this plot it is easily seen that were are over 9000 apartments with 2.5 bathrooms. We can see the relevant distributions of each count. The last plot we have shows log price, accommodates and bedrooms. This plot compares/pairs each of those which one another. Each of these plots gives a clear explanation and visualization of different LA properties regarding housing, and pricing.**
  
  Step II: Prediction (20 points)
A multiple regression model with the outcome variable log_price .

**In order to create a multiple regression model for our dataset, I first set a seed value so that our results would be reproducible in the future. Then we created a data partition to split the data set 70/30 and assigned the 70% to the models training set and the remaining 30% to the test set.**
  
  **After dividing the data set, I used the lm() function in R, feeding the model all of the variables in our dataset in order to determine what were the significant factors. After reviewing this output, we reset the model removing factors that were of lower significance. At this point the linear model derived the log price from room_type, number of bathrooms, if the host identity was verified, the longitude of the property and the number of bedrooms The resulting updated model is somewhat less accurate than using all of the variables, with the R squared value falling from 0.7757 to 0.6765, but the resulting model is still strong.**
  
  **The final equation derived for determining the log price of a property in LA was determined to be log_price = -90.766686 x bathrooms(0.153775) x host_identity_verified(0.027347) x longitude(-0.804093) x bedrooms(0.273425) x Private room(-0.638041) or -90.766686 x bathrooms(0.153775) x host_identity_verified(0.027347) x longitude(-0.804093) x bedrooms(0.273425) x Shared room(-1.366496)**
  
  ```{r}
train_ind <-createDataPartition(y=clean.df$log_price,p=0.7, list=FALSE)

log_train <- clean.df[train_ind, ]
log_test <- clean.df[-train_ind, ]

model <- lm(log_price ~ property_type + room_type + bathrooms + cleaning_fee + instant_bookable + host_has_profile_pic + host_identity_verified + host_response_rate + latitude + longitude + neighbourhood + number_of_reviews + zipcode + bedrooms, data=log_train)

model2 <- lm(log_price ~ room_type + bathrooms + host_identity_verified +
               longitude + bedrooms, data=log_train)

summary(model)
summary(model2)
pred <- predict(model2, log_train)
accuracy(pred, log_train$log_price)
pred2 <- predict(model2, log_test)
accuracy (pred2, log_test$log_price)
```


**The r-squared of the model is 0.6765. This means that 67.65% of the variance in the measure of log_price can be predicted by by the factors included in the model.**
  
  **The RMSE of the model is 0.3982022. This means that the mean value of the error between the predicted log_price by the model and the actual value in the test data is 0.3982. i.e.. The log_price calculated by the model is wrong on average by 0.3982. **
  
  
  Step III: Classification
```{r}
df_la <- clean.df

amenities_count <- as.data.frame(sapply(strsplit(df_la$amenities, ","), length))
colnames(amenities_count) <- "number_of_amenities"

amenities_count <- amenities_count %>%
  mutate(numb_of_amenities = if_else(number_of_amenities >= 20, "high",
                                     if_else(number_of_amenities >=10, "medium", "low")))
table(amenities_count$numb_of_amenities)

dummy_properties <- as.data.frame(model.matrix( ~ property_type+0, data = df_la))
dummy_room <- as.data.frame(model.matrix( ~ room_type+0, data = df_la)) 
dummy_bedtype <- as.data.frame(model.matrix( ~ bed_type+0, data = df_la))
dummy_instantbook <- as.data.frame(model.matrix( ~ instant_bookable+0, data = df_la))
dummy_nieghbourhood <- as.data.frame(model.matrix( ~ neighbourhood+0, data = df_la))
dummy_amenities <- as.data.frame(model.matrix( ~ numb_of_amenities+0, data = amenities_count))

df_la2 <- cbind(df_la, dummy_amenities, dummy_nieghbourhood, dummy_instantbook, dummy_bedtype,
                dummy_room, dummy_properties)

knn_la <- df_la2[c(-1, -3, -4, -5, -6, -8, -9, -11, -12, -13, -14, -15, -16, -17, -18,
                   -19, -20, -21, -22, -23, -25, -26, -27)]
sample_df_knn_la <- sample_n(knn_la, 17114)
train.la <- slice(sample_df_knn_la, 1:10268)
test.la <- slice(sample_df_knn_la, 10269:17114)
colnames(knn_la)
sample_df_knn_la.norm <- sample_df_knn_la
train.la.norm <- train.la
test.la.norm <- test.la

normv <- preProcess(train.la[, -3], method=c("center", "scale"))
sample_df_knn_la.norm[, -3] <- predict(normv, sample_df_knn_la[, -3])
train.la.norm[, -3] <- predict(normv, train.la[, -3])
test.la.norm[, -3] <- predict(normv, test.la[, -3])

#checking for optimal k

train.la.norm$cleaning_fee <- as.factor(train.la.norm$cleaning_fee)
test.la.norm$cleaning_fee <- as.factor(test.la.norm$cleaning_fee)

accuracy.df <- data.frame(k = seq(1, 30, 1), accuracy = rep(0, 30))

for(i in 1:30) {
  knn.pred <- knn(train = train.la.norm[, -3], test.la.norm[, -3] , 
                  cl = train.la[, 3], k = i)
  
  accuracy.df[i, 2] <- confusionMatrix(knn.pred, test.la.norm[, 3])$overall[1]
}

accuracy.df

plot(accuracy.df$k, accuracy.df$accuracy, main = "Accuracy of different K values",
     ylab = "Accuracy", xlab = "K Values")

nn <- knn(train = train.la.norm[, -3], test.la.norm[, -3], 
          cl = train.la[, 3], k = 9)

knn.pred1 <- knn(train = train.la.norm[, -3], test.la.norm[, -3] , 
                 cl = train.la[, 3], k = 9)

```


**After thinking about the different factors that could even remotely have a role to play when influencing  the decision to keep a cleaning fee. The amenities variable tells us how many amenities are there in each listing but they need to be grouped into different categories of high, medium and low. The reason behind this is that if a property has more amenities it may require more upkeep and hence a cleaning fee. We felt that this relationship of - more or larger the variable the higher the likelihood of a cleaning fee - can also be applied to the variables, beds, bedrooms, log price, and bathrooms. Neighborhood can also be a factor in determining cleaning fees as more high-end neighborhoods would tend to have better and more expensive properties that would require a cleaning fee. If a place can be booked instantly it may require more costs to clean up quickly so it can increase the likelihood of a cleaning fee. A private room or shared room is smaller than an entire apartment which may require more upkeep and hence a cleaning fee, similarly a fouton demands lesser maintenance and hence less likely to have a cleaning fee as compared to a real bed having a cleaning fee.**
  
  **Since the KNN model only takes in numerical variables, categorical variables such as neighborhood and number of amenities (high, medium, low), property type, bed type, instant book, and room tpye have to be turned into dummy variables in order to be used in the model. All dummies variables are used as compared to in linear models where one variable is dropped as it can be inferred from the rest of the data.**
  **KNN models work by creating an n (number of variables) dimensional space and plotting points based on the value of the variables. New points added in are plotted according to their variable values and then classified based on their distance to nearest K points. **
  **To check for how many K Neighbors would be optimum in classifying the cleaning fee, the dataset was divided into two different sets, training and testing set. The model was then created based on the training set for K from 1 to 30 and checked for accuracy on the test set. The k value which showed the highest accuracy and the lowest computational time (as k increases so does computation time) was chosen as the optimum K value. In this model it as K = 9. A plot of the values with K on the x axis and accuracy on the y axis clearly shows that after K =9 accuracy does not increase significantly and hence is the best value to use. The accuracy at this K value is at around 84%. Classifying the cleaning fee based on a naive rule i.e. placing all values into the majority class would also give around 84% percent accuracy as 84% of the records have a cancellation fee. This could suggest that this model is not that useful in predicting whether or not a cleaning fee should be applied.**
  
  Part II . Naive Bayes

```{r}
summary(df_la$log_price)

df_la.p <- df_la %>%
  mutate(pricing = if_else(log_price >= 5.106, "Pricey Digs", 
                           if_else(log_price >= 4.701, "Above Average", 
                                   if_else(log_price >= 4.248, "Below Average","Student Budget"))))

table(df_la.p$pricing)

df_la.p$pricing <- as.factor(df_la.p$pricing)

df_la.p <- cbind(df_la.p, amenities_count)

#picking variables 
sample_df_nb_la <- sample_n(df_la.p, 17114)
train.la.nb <- slice(sample_df_nb_la, 1:10268)
test.la.nb <- slice(sample_df_nb_la, 10269:17114)

#With Neighbourhoods included as variable type
df_la.nb <- train.la.nb[c(3, 4, 18, 23, 32, 30)]
df_la.nbv <- test.la.nb[c(3, 4, 18, 23, 32, 30)]

nbmodel <- naiveBayes(pricing ~ ., data = df_la.nb)
nbmodel

predicted_valid.nb <- predict(nbmodel, newdata  = df_la.nbv, type = "class")
confusionMatrix(predicted_valid.nb, test.la.nb$pricing)
#0.53 accuracy. 

#without neighborhood included. Instead  number of bedrooms is included.
df_la.nb <- train.la.nb[c(3, 4, 18, 28, 32, 30)]
df_la.nbv <- test.la.nb[c(3, 4, 18, 28, 32, 30)]

nbmodel <- naiveBayes(pricing ~ ., data = df_la.nb)
nbmodel

predicted_valid.nb <- predict(nbmodel, newdata  = df_la.nbv, type = "raw")


predicted_valid.nb <- predict(nbmodel, newdata  = df_la.nbv, type = "class")
predicted_valid.nb[1:100]
confusionMatrix(predicted_valid.nb, test.la.nb$pricing)
#0.55 accuracy.


fic_apt <- data.frame(property_type = "loft", room_type = "Private Room", 
                      instant_bookable = "t", bedrooms = 2, 
                      numb_of_amenities = "high")

predicted_fic.nb <- predict(nbmodel, newdata  = fic_apt, type = "class")
predicted_fic.nb
```

**Price bins are created by looking at the distribution of log price. Anything above the 3rd quartile of prices is considered pricey digs, between the mean value and the third quartile is considered above average, below the mean till the first quartile is below average and anything under that is considered student budget**
  **Naive Bayes works by calculating probabilities of when something occurs if something else has occurred. For example if a an listing is a shared room how many times does that fall into pricey digs, above average, below average, and student budget. When a new data point is introduced it will calculate the scores for the new point based on these probabilities and classify the new data point based on which class receives the highest score. The fictional data point created for our question falls into the pricey digs category. ** 
  **The first thing needs to be addressed with regards to variable selection is the exclusion of neighborhood from the training model. As it is known that when it comes to property, location is everything. However, when training the model with neighborhood the accuracy was actually lesser than when the variable neighborhood was replaced with the variable number of bedrooms (53%<55%). The model with neighborhood has been included to demonstrate the lower accuracy in the model.**
  **The other variables chosen were:**
  **1. Property type as some types of properties cost more than others which will directly impact the price.**
  **2. Room type as a private room will typically cost more than a shared room and a entire apartment more than both.**
  **3. Instant bookable is a benefit that adds convenience and can charged for additionally.**
  **4. Number of amenities - Keeping more amenities increases costs for the owner which will directly impact the price.**
  **5. Number  of bedrooms - Speaks to size of the house and typically larger houses tend to be cost more**
  **Once the Naive Bayes model is built on the training set it is used to predict values from the validation set. The values predicted by the model are compared to the actual values in the validation set. The accuracy is measured based on how many outcomes are properly predicted. In our model it is around 55%. **
  
  
  Part III . Classification Tree

```{r}
df_la.dt <- cbind(df_la[,-1], amen_count = amenities_count$number_of_amenities)


df_la.dt$cancellation_policy <- as.factor(df_la.dt$cancellation_policy)
df_la.dt$property_type <- as.factor(df_la.dt$property_type)

df_la.dt <- dplyr::select(.data = df_la.dt, log_price, property_type, room_type, amen_count, cancellation_policy, accommodates,
                          bathrooms, cleaning_fee, host_identity_verified, instant_bookable,
                          bedrooms, beds)

sampling.dt <- sample_n(df_la.dt, 17114)
train.dt <- slice(sampling.dt, 1:10268)
test.dt <- slice(sampling.dt, 10269:17114)

decision_tree <-  rpart(cancellation_policy ~ .,
                        data = train.dt, method = "class", cp = 0.000, xval = 5)
xerror <- printcp(decision_tree)
xerror1 <- as.data.frame(xerror)
m <- which.min(xerror1$xerror) #4
cp_value <- xerror1[4, 1]

decision_tree2 <- rpart(cancellation_policy ~ .,
                        data = train.dt, method = "class", cp = cp_value)
rpart.plot(decision_tree2 ,box.palette = "green")

prop.table(table(test.dt$cancellation_policy))

predict.dt <- predict(decision_tree2, test.dt, type = "class")
confusionMatrix(predict.dt, test.dt$cancellation_policy)
```


**Ideally I wanted to build a tree with all variables as features for the model however because of computational constraints we were unable to run such a model even after giving it few hours. What I did next was select features that I thought might effect the cancellation policy. Instant bookable, host identity verified, and cleaning fee are all variables that can be used to try and estimate the type of person who is hosting as these are decisions that can be made by any owner regardless of the type of property they own.  This can help us identify the type of person and their cancellation policy.** 
  **Other variables used such as property type, room type, bedrooms, bathrooms, beds and, accommodates are all different features of an apartment. Identifying types of apartments through their features might shed light about the type of cancellation policy that is used for them.** 
  **Using the training set to build the model and then test on the validation set we compared different levels for the tree and a suitable cp value by looking at the minimum cross validation error. The resulting model that is built on the CP value that  corresponding to the minimum cross validation error uses beds, property type and cleaning fee to determine cancellation policy. Interestingly the model never predicts any of the listings to have a moderate of super strict cancellation policy. It is split between flexible (around 14% of the records and strict (85%) of the time. It should be noted that this model has an accuracy of just 52%. This may may tell us predicting the cancellation policy is not feasible based on the variables that are provided. Or alternatively that the decision tree is not a suitable algorithm for such a task. However, that being said using the naive rule there would be only a 48% accuracy and so it is still more accurate than that which shows that there is some merit in using the model.**
  
  Step IV: Clustering (15 points)


```{r}
clean1.df <- cbind(clean.df,amenities_count)
kmeans.df <- clean1.df %>%
  filter(between(latitude, 34.038191, 34.128067))
kmeans.df <- kmeans.df %>%
  filter(between(longitude, -118.375405, -118.274415))
colnames(kmeans.df)
# write.csv(kmeans.df, file = "kmeans.csv")
kmeans2.df <- kmeans.df[c(2, 6:7, 20:21, 24:25, 28:30)]
kmeans2.df <- mutate_if(kmeans2.df, is.numeric, scale)

#function compute total within-cluster sum of square
wss <- function(k) {kmeans(kmeans2.df, k, nstart = 15)$tot.withinss}
k.values <- 1:15
wss_values <- map_dbl(k.values, wss)
plot(k.values, wss_values, type = "b", pch = 19, frame = FALSE, main = "Elbow Plot")

km.df <- kmeans(kmeans2.df, 11)
kmeans.df <- mutate(.data=kmeans.df, cluster=km.df$cluster)
kmeans3.df <- kmeans.df[c(2, 6:7, 20:21, 23:25, 28:30, 32)]

kmeans.df %>%
  group_by(neighbourhood)  %>%
  summarise_at(c("cluster"), mean, na.rm = TRUE)

aggregate(kmeans3.df, by=list(cluster=kmeans.df$cluster), mean)
head(kmeans.df$cluster, "neighbourhood")
# write.csv(kmeans.df, file = "kmeans2.csv")
```

**In an effort to reduce this task to a more manageable number of neighborhoods, I to limit the geographic area of the analysis to the region north of Interstate 10 between La Cienega Blvd in the west and I110 in the east up to the Hollywood sign in the Hollywood Hills. This was achieved by filtering the dataframe between latitude 34.038191 and 34.128067 and longitude -118.375405 and -118.274415. We then paired down the dataframe to simply variables that were numeric and scaled them to even out the model. An elbow plot was created to determine the optimal number of clusters (11) and then kmeans() was run for that number of clusters.**
  
  
  Conclusions 

**This project appears to be reflective of the kind of experiences that someone could expect to go through when asked to derive actionable intelligence from a raw collection of data. The data needed to be gathered and scrubbed for errors that would effect the analysis. Missing data points needed to be evaluated and addressed. This is followed by a systematic effort to tease actionable information out of a morass of data. Every step in the process gave us additional insight into the rental market in our assigned area, which will only lead to better decisions regarding the market.**
  
  **When looking at the multiple regression analysis, I determined not only the average expected price for a rental property in the region we were also able to determine the most significant factors in determining that price. This would allow a private homeowner to determine if it is worth putting their spare bedroom up for rent by giving them a market estimate of their rentals value. It would also be useful for a rental investor looking to expand their portfolio, since they could investigate the best locations to purchase and what features their next rental property should have to make the highest rate of return.**
  
  **The classification and clustering models have applications for individual renters and companies. For the individual renter, determining the specific price point for their property based on it's features can be tedious and overwhelming. By assigning their property to a more manageble range in a bin, pricing can be estimated without pouring over every detail. At the same time a travel agency can make good use of the binning created by our Naive Bayes model to provide renters with a variety of options while staying within their price range. Reducing analysis paralasis on the part of renters by grouping offerings would increase customer satisfaction and increase sales. AirBnB could also use the classification models to fill in the blanks for listings, either as a service for the landlords or the renters. Landlords could enter in the data about their properties and AirBnB could use the models to predict if they should have a given feature, such as a cleaning fee or a strict cancelation policy. AirBnB could then make recomendations to landlords based on those predictions to encourage the addition of missing features so the landlords don't miss out on potential fees. Conversly, AirBnB could recommend removing features if those features would potentially cause the property to lose rentals because they exist.**
  